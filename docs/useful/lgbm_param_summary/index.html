<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>LightGBM(gbdt)のパラメータ,Tuningの個人的まとめ - mosamosa blog</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/blog/css/style.css">
	

	<link rel="shortcut icon" href="/blog/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/blog/" title="mosamosa blog" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">mosamosa blog</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LightGBM(gbdt)のパラメータ,Tuningの個人的まとめ</h1>
			
		</header><div class="content post__content clearfix">
			<p>初手LightGBMは機械学習系だと割とやると思うんですが、いざobjectiveとかパラメータTuningをするたびにドキュメントを読むことになっているので、まとめようと思いました。</p>
<p>基本は<a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">ドキュメント</a>を抜粋した日本語訳に近くなると思います。</p>
<h1 id="objective">Objective</h1>
<p>よく使うのだけにします。</p>
<ul>
<li>&ldquo;regression&rdquo; : mean_squared_errorを誤差関数として使う回帰です。</li>
<li>&ldquo;regression_l1&rdquo; : mean_absolute_errorを誤差関数として使う回帰です。</li>
<li>&ldquo;binary&rdquo; : 二値分類のloglossです。</li>
<li>&ldquo;multiclass&rdquo; : 多クラス分類、softmaxです。&ldquo;num_class&quot;でクラス数も一緒に与えて上げる必要があります。</li>
<li>&ldquo;multiclassova&rdquo; : 多クラス分類をOneVsAllでときます。同様に&quot;num_class&quot;でクラス数も一緒に与えて上げる必要があります。</li>
<li>&ldquo;cross_entropy&rdquo; : クロスエントロピーです。</li>
</ul>
<h1 id="学習に関わるパラメータ">学習に関わるパラメータ</h1>
<ul>
<li>&ldquo;num_iterations&rdquo; : 学習のイテレーション回数を指定します。defalut 100です。</li>
<li>&ldquo;learning_rate&rdquo; : learning_rateです。default 0.1です。</li>
<li>&ldquo;num_leaves&rdquo; : <strong>木の複雑度をコントロールするメインパラメータです</strong>分岐の終着点の数を決めます。default 31です。</li>
<li>&ldquo;seed&rdquo; : random seedです。<strong>これを決めれば色々ある他のseedがすべて決まります</strong> default Noneなのでか必ず設定しましょう。</li>
<li>&ldquo;max_depth&rdquo; : 木の最大深さを決めます。defaultの-1は上限無しなので、ここも必ず設定したほうがいいと思います。</li>
<li>&ldquo;min_data_in_leaf&rdquo; : 葉に行き着くデータがこれより少なくならない用になります。default 20です。</li>
<li>&ldquo;bagging_fraction&rdquo; : baggingで選択されるサンプルの割合です。default 1.0で、baggingは無効化されています。また、<strong>baggingするには&quot;bagging_freq&quot;も正の値にしなくてはなりません。</strong></li>
<li>&ldquo;bagging_freq&rdquo; : 何回に一回baggingするかです。こちらだけセットしてもやはりbaggingは出来ず、<strong>baggingするには&quot;bagging_fraction&quot;が1未満である必要があります。</strong></li>
<li>&ldquo;feature_fraction&rdquo; : 1.0未満の値にすると、特徴量の一部を削減して学習を行う用になります。default 1.0です。</li>
<li>&ldquo;early_stopping_round&rdquo; : early stoppingのpatienceです。するときは設定しましょう。</li>
<li>&ldquo;lambda_l1&rdquo; : L1正則化です。</li>
<li>&ldquo;lambda_l2&rdquo; : L2正則化です。</li>
<li>&ldquo;verbosity&rdquo; : &lt; 0: Fatal, = 0: Error (Warning), = 1: Info, &gt; 1: Debug　だそうです。default 1です。</li>
</ul>
<h1 id="parameter-tuning">parameter Tuning</h1>
<p>おおよその探索範囲表です(まずはこのあたりをGridSearchする)
<strong>個人的な体感によるものですので、当然ベストではないですし、betterですらない可能性があることをご承知ください</strong></p>
<p>個人的優先度順になってるので、計算時間が無いときはこの上からN個だけとかで探索します。</p>
<table>
<thead>
<tr>
<th>パラメータ名</th>
<th>探索範囲</th>
<th>備考</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_leaves</td>
<td>7,15,31</td>
<td>大ほどOverFit, 2^(mad_depth)* 0.7程度に決め打ちもあり。</td>
</tr>
<tr>
<td>max_depth</td>
<td>5,7,9</td>
<td>大ほどOverFit</td>
</tr>
<tr>
<td>min_data_in_leaf</td>
<td>20,30,50</td>
<td>小ほどOverFit</td>
</tr>
<tr>
<td>bagging_fraction</td>
<td>0.8,0.9</td>
<td>大ほどOverFit?</td>
</tr>
<tr>
<td>bagging_freq</td>
<td>1,3</td>
<td>小ほどOverFit?</td>
</tr>
<tr>
<td>feature_fraction</td>
<td>0.9,1.0</td>
<td>大ほどOverFit?</td>
</tr>
<tr>
<td>lambda_l1</td>
<td>0,2,5</td>
<td>小ほどOverFit。正直どのくらいがいいのか全くわからないので、下手に弄らないことも多し。</td>
</tr>
<tr>
<td>lambda_l2</td>
<td>0,2,5</td>
<td>小ほどOverFit。正直どのくらいがいいのか全くわからないので、下手に弄らないことも多し。</td>
</tr>
</tbody>
</table>
<p>bagging_fractionや,feature_fractionを設定しないとrandom_stateを変えても結果が変わらなくなるので、パラメータTuningの時間が無い時+ensemble(or random seed average)する前提のときはこのあたりはtuning出来なくてもに0.8〜0.9にとりあえずしといた方が、混ぜた結果は強くなるのではという気がします。</p>
<p>その他learning_rateを下げてiterationを伸ばすと当然良くなると思われますが、自明なのでやるにしても最後です。</p>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/blog/tags/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9/" rel="tag">データサイエンス</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/blog/tags/%E3%81%BE%E3%81%A8%E3%82%81%E8%A8%98%E4%BA%8B/" rel="tag">まとめ記事</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 mosamosa blog.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/blog/js/menu.js"></script>
</body>
</html>